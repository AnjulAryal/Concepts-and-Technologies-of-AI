{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Step -1- Data Understanding, Analysis and Preparations:**\n",
        "In this step we will read the data, understand the data, perform some basic data cleaning, and store everything\n",
        "in the matrix as shown below.\n",
        "\n",
        "**• Requirements:**\n",
        "Dataset → student.csv\n",
        "\n",
        "**• Decision Process:**\n",
        "In this step we will define the objective of the task.\n",
        "\n",
        "**– Objective of the Task -**\n",
        "To Predict the marks obtained in writing based on the marks of Math and Reading."
      ],
      "metadata": {
        "id": "DslsUFe5vPZZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To - Do - 1:**\n",
        "1. Read and Observe the Dataset.\n",
        "2. Print top(5) and bottom(5) of the dataset {Hint: pd.head and pd.tail}.\n",
        "3. Print the Information of Datasets. {Hint: pd.info}.\n",
        "4. Gather the Descriptive info about the Dataset. {Hint: pd.describe}\n",
        "5. Split your data into Feature (X) and Label (Y)."
      ],
      "metadata": {
        "id": "24jywNhLvRHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Dataset:\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Concept and techologies of AI/student (1).csv\")\n",
        "\n",
        "#Print top(5) and bottom(5) of the dataset:\n",
        "print(\"Top five dataset:\",df.head())\n",
        "print(\"Bottom five dataset:\",df.tail())\n",
        "\n",
        "#Print the Information of Datasets:\n",
        "df.info()\n",
        "\n",
        "#Gather the Descriptive info about the Dataset:\n",
        "df.describe()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        },
        "id": "jP21xyAvvTLE",
        "outputId": "4c3df9da-e957-4a90-a2bb-2da9c607a618"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top five dataset:    Math  Reading  Writing\n",
            "0    48       68       63\n",
            "1    62       81       72\n",
            "2    79       80       78\n",
            "3    76       83       79\n",
            "4    59       64       62\n",
            "Bottom five dataset:      Math  Reading  Writing\n",
            "995    72       74       70\n",
            "996    73       86       90\n",
            "997    89       87       94\n",
            "998    83       82       78\n",
            "999    66       66       72\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype\n",
            "---  ------   --------------  -----\n",
            " 0   Math     1000 non-null   int64\n",
            " 1   Reading  1000 non-null   int64\n",
            " 2   Writing  1000 non-null   int64\n",
            "dtypes: int64(3)\n",
            "memory usage: 23.6 KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Math      Reading      Writing\n",
              "count  1000.000000  1000.000000  1000.000000\n",
              "mean     67.290000    69.872000    68.616000\n",
              "std      15.085008    14.657027    15.241287\n",
              "min      13.000000    19.000000    14.000000\n",
              "25%      58.000000    60.750000    58.000000\n",
              "50%      68.000000    70.000000    69.500000\n",
              "75%      78.000000    81.000000    79.000000\n",
              "max     100.000000   100.000000   100.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-00576bd6-d6b3-442b-9bf2-51f3939dc964\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Math</th>\n",
              "      <th>Reading</th>\n",
              "      <th>Writing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>67.290000</td>\n",
              "      <td>69.872000</td>\n",
              "      <td>68.616000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>15.085008</td>\n",
              "      <td>14.657027</td>\n",
              "      <td>15.241287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>13.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>14.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>58.000000</td>\n",
              "      <td>60.750000</td>\n",
              "      <td>58.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>68.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>69.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>78.000000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>79.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-00576bd6-d6b3-442b-9bf2-51f3939dc964')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-00576bd6-d6b3-442b-9bf2-51f3939dc964 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-00576bd6-d6b3-442b-9bf2-51f3939dc964');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-053e7358-dc01-472e-bc55-323902e611a8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-053e7358-dc01-472e-bc55-323902e611a8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-053e7358-dc01-472e-bc55-323902e611a8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Math\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 334.70993839737343,\n        \"min\": 13.0,\n        \"max\": 1000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          67.29,\n          68.0,\n          1000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Reading\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 333.8589622553041,\n        \"min\": 14.65702713528377,\n        \"max\": 1000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          69.872,\n          70.0,\n          1000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Writing\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 334.45996524707175,\n        \"min\": 14.0,\n        \"max\": 1000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          68.616,\n          69.5,\n          1000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To - Do - 2:**\n",
        "1. To make the task easier - let’s assume there is no bias or intercept.\n",
        "2. Create the following matrices:"
      ],
      "metadata": {
        "id": "-T_cDBtUwJFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of features (d) and samples (n)\n",
        "d = 2\n",
        "n = 5\n",
        "\n",
        "# Feature matrix (d x n)\n",
        "X = np.array([\n",
        "    [48, 62, 79, 76, 59],   # Math\n",
        "    [68, 81, 80, 83, 64]    # Reading\n",
        "])\n",
        "\n",
        "# Weight vector (d x 1)\n",
        "W = np.array([\n",
        "    [0.5],\n",
        "    [0.7]\n",
        "])\n",
        "\n",
        "# Target vector (n x 1)\n",
        "Y = np.array([\n",
        "    [63],\n",
        "    [72],\n",
        "    [78],\n",
        "    [79],\n",
        "    [62]\n",
        "])\n",
        "\n",
        "# Prediction\n",
        "Y_pred = W.T @ X"
      ],
      "metadata": {
        "id": "cqbvtk1GwOEI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To - Do - 3:**\n",
        "1. Split the dataset into training and test sets.\n",
        "2. You can use an 80-20 or 70-30 split, with 80% (or 70%) of the data used for training and the rest\n",
        "for testing."
      ],
      "metadata": {
        "id": "ufdWukLGxC_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Features and target (sample-wise representation)\n",
        "X_data = np.array([\n",
        "    [48, 68],\n",
        "    [62, 81],\n",
        "    [79, 80],\n",
        "    [76, 83],\n",
        "    [59, 64]\n",
        "])\n",
        "\n",
        "Y_data = np.array([63, 72, 78, 79, 62])\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X_data, Y_data, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "qWUM9KlnxKLf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step -2- Build a Cost Function:**\n",
        "Cost function is the average of loss function measured across the data point. As the cost function for Regression\n",
        "problem we will be using Mean Square Error which is given by:\n"
      ],
      "metadata": {
        "id": "lhY_HF7oxNZi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To - Do - 4:**\n",
        "\n",
        "\n",
        "-Feel free to build your own code or complete the following code:\n",
        "**Building a Cost Function:**"
      ],
      "metadata": {
        "id": "aIrvyoYRxUR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "#Define the cost function\n",
        "def cost_function(X, Y, W):\n",
        "  \"\"\" Parameters:\n",
        "  This function finds the Mean Square Error.\n",
        "  Input parameters:\n",
        "  X: Feature Matrix\n",
        "  Y: Target Matrix\n",
        "  W: Weight Matri\\\n",
        "\n",
        "  \\\n",
        "  Output Parameters:\n",
        "  cost: accumulated mean square error.\n",
        "  \"\"\"\n",
        "  # Your code here:\n",
        "  xt = np.transpose(X)\n",
        "  ypred= np.dot(W,xt)\n",
        "  loss=(ypred-Y)**2\n",
        "  cost=np.sum(loss)/ X.shape[0] #len(Y)\n",
        "  return cost\n",
        "\n"
      ],
      "metadata": {
        "id": "r5toYUiaxVNw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To - Do - 5:**\n",
        "\n",
        "-Make sure your code at To - Do - 4 passed the following test case:\n",
        "\n",
        "**Testing a Cost Function:**"
      ],
      "metadata": {
        "id": "-zYYiHMMxYw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test case\n",
        "X_test = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "Y_test = np.array([3, 7, 11])\n",
        "W_test = np.array([1, 1])\n",
        "cost = cost_function(X_test, Y_test, W_test)\n",
        "if cost == 0:\n",
        " print(\"Proceed Further\")\n",
        "else:\n",
        " print(\"something went wrong: Reimplement a cost function\")\n",
        "print(\"Cost function output:\", cost_function(X_test, Y_test, W_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AfMQUL_xgz9",
        "outputId": "4598946e-e488-4f06-aa62-bea940e7865f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proceed Further\n",
            "Cost function output: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step -3- Gradient Descent for Simple Linear Regression:**"
      ],
      "metadata": {
        "id": "b0eFdeQWxiws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To - Do - 6:**\n",
        "\n",
        "-Implement your code for Gradient Descent; Either fill the following code or write your own:\n",
        "\n",
        "**Gradient Descent from Scratch:**"
      ],
      "metadata": {
        "id": "uEVffG8Gxmq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, Y, W, alpha, iterations):\n",
        "  \"\"\"\n",
        "  Perform gradient descent to optimize the parameters of a linear regression model.\n",
        "  Parameters:\n",
        "  X (numpy.ndarray): Feature matrix (m x n).\n",
        "  Y (numpy.ndarray): Target vector (m x 1).\n",
        "  W (numpy.ndarray): Initial guess for parameters (n x 1).\n",
        "  alpha (float): Learning rate.\n",
        "  iterations (int): Number of iterations for gradient descent.\n",
        "  Returns:\n",
        "  tuple: A tuple containing the final optimized parameters (W_update) and the history of cost values\n",
        "  .\n",
        "  W_update (numpy.ndarray): Updated parameters (n x 1).\n",
        "  cost_history (list): History of cost values over iterations.\n",
        "  \"\"\"\n",
        "  # Initialize cost history\n",
        "  cost_history = [0] * iterations\n",
        "  # Number of samples\n",
        "  m = len(Y)\n",
        "  for iteration in range(iterations):\n",
        "    # Step 1: Hypothesis Values\n",
        "    Y_pred = np.dot(X, W)\n",
        "    # Step 2: Difference between Hypothesis and Actual Y\n",
        "    loss = Y_pred - Y\n",
        "    # Step 3: Gradient Calculation\n",
        "    dw = np.dot(X.T, loss) / m #we can use(.T) or (np.Transpose) for transpose of X\n",
        "    # Step 4: Updating Values of W using Gradient\n",
        "    W_update = W - alpha * dw\n",
        "    # Step 5: New Cost Value\n",
        "    cost = cost_function(X, Y, W_update)\n",
        "    cost_history[iteration] = cost\n",
        "    return W_update, cost_history"
      ],
      "metadata": {
        "id": "ZeBEDz6nxofG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To - Do - 7:**\n",
        "\n",
        "-Make sure following Test Case is passe by your code from To - Do - 6 or your Gradient Descent\n",
        "Implementation:\n",
        "\n",
        "**Test Code for Gradient Descent function:**"
      ],
      "metadata": {
        "id": "q0Ms1sT6xrc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate random test data\n",
        "np.random.seed(0) # For reproducibility\n",
        "X = np.random.rand(100, 3) # 100 samples, 3 features\n",
        "Y = np.random.rand(100)\n",
        "W = np.random.rand(3) # Initial guess for parameters\n",
        "# Set hyperparameters\n",
        "alpha = 0.01\n",
        "iterations = 1000\n",
        "# Test the gradient_descent function\n",
        "final_params, cost_history = gradient_descent(X, Y, W, alpha, iterations)\n",
        "# Print the final parameters and cost history\n",
        "print(\"Final Parameters:\", final_params)\n",
        "print(\"Cost History:\", cost_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90z4IZO8xvID",
        "outputId": "4fc61a82-b0be-4369-df76-8bef5b5b4e58"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Parameters: [0.3996496  0.92745322 0.09826523]\n",
            "Cost History: [np.float64(0.21422394189320307), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step -4- Evaluate the Model:**\n",
        "Evaluation in Machine Learning measures the goodness of fit of your build model. Lets see How Good is\n",
        "model we designed above, as discussed in the class for regression we can use following function as evaluation\n",
        "measure."
      ],
      "metadata": {
        "id": "Ik-gn0mCxxBo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To - Do - 8:**\n",
        "\n",
        "-Implementation of RMSE in the Code - Complete the following code or write your own:\n",
        "\n",
        "**Code for RMSE:**"
      ],
      "metadata": {
        "id": "O-kV6o5Vx6AC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation - RMSE\n",
        "def rmse(Y, Y_pred):\n",
        "  \"\"\"\n",
        "  This Function calculates the Root Mean Squres.\n",
        "  Input Arguments:\n",
        "  Y: Array of actual(Target) Dependent Varaibles.\n",
        "  Y_pred: Array of predeicted Dependent Varaibles.\n",
        "  Output Arguments:\n",
        "  rmse: Root Mean Square.\n",
        "  \"\"\"\n",
        "  rmse = np.sqrt(np.sum((Y - Y_pred)**2)/len(Y))\n",
        "  return rmse"
      ],
      "metadata": {
        "id": "anSk80a-x64C"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To - Do - 9**\n",
        "\n",
        "-Implementation in the Code:\n",
        "Complete the following code or write your own for r2 loss:\n",
        "\n",
        "\n",
        "**Code for R-Squared Error:**"
      ],
      "metadata": {
        "id": "l79YbVD8x-6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation - R2\n",
        "def r2(Y, Y_pred):\n",
        "  \"\"\"\n",
        "  This Function calculates the R Squared Error.\n",
        "  Input Arguments:\n",
        "  Y: Array of actual(Target) Dependent Varaibles.\n",
        "  Y_pred: Array of predeicted Dependent Varaibles.\n",
        "  Output Arguments:\n",
        "  rsquared: R Squared Error.\n",
        "  \"\"\"\n",
        "  mean_y = np.mean(Y)\n",
        "  ss_tot = np.sum((Y - mean_y)**2)\n",
        "  ss_res = np.sum((Y - Y_pred)**2)\n",
        "  r2 =  1- (ss_res/ss_tot)\n",
        "  return r2"
      ],
      "metadata": {
        "id": "HQKsnsL6x_jB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step -5- Main Function to Integrate All Steps:**\n",
        "\n",
        "In this section, we will create a main function that integrates the data loading, preprocessing, cost function,\n",
        "gradient descent, and model evaluation. This will help in running the entire workflow with minimal effort."
      ],
      "metadata": {
        "id": "SgdkJBHDyFNR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To - Do - 10:**\n",
        "\n",
        "We will define a function that:\n",
        "1. Loads the data and splits it into training and test sets.\n",
        "2. Prepares the feature matrix (X) and target vector (Y).\n",
        "3. Defines the weight matrix (W) and initializes the learning rate and number of iterations.\n",
        "4. Calls the gradient descent function to learn the parameters.\n",
        "5. Evaluates the model using RMSE and R2"
      ],
      "metadata": {
        "id": "yWua4J8SyHxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Main Function\n",
        "def main():\n",
        "  # Step 1: Load the dataset\n",
        "  data = pd.read_csv(\"/content/drive/MyDrive/Concept and techologies of AI/student (1).csv\")\n",
        "  # Step 2: Split the data into features (X) and target (Y)\n",
        "  X = data[['Math', 'Reading']].values # Features: Math and Reading marks\n",
        "  Y = data['Writing'].values # Target: Writing marks\n",
        "  # Step 3: Split the data into training and test sets (80% train, 20% test)\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "  # Step 4: Initialize weights (W) to zeros, learning rate and number of iterations\n",
        "  W = np.zeros(X_train.shape[1]) # Initialize weights\n",
        "  alpha = 0.00001 # Learning rate\n",
        "  iterations = 1000 # Number of iterations for gradient descent\n",
        "  # Step 5: Perform Gradient Descent\n",
        "  W_optimal, cost_history = gradient_descent(X_train, Y_train, W, alpha, iterations)\n",
        "  # Step 6: Make predictions on the test set\n",
        "  Y_pred = np.dot(X_test, W_optimal)\n",
        "  # Step 7: Evaluate the model using RMSE and R-Squared\n",
        "  model_rmse = rmse(Y_test, Y_pred)\n",
        "  model_r2 = r2(Y_test, Y_pred)\n",
        "  # Step 8: Output the results\n",
        "  print(\"Final Weights:\", W_optimal)\n",
        "  print(\"Cost History (First 10 iterations):\", cost_history[:10])\n",
        "  print(\"RMSE on Test Set:\", model_rmse)\n",
        "  print(\"R-Squared on Test Set:\", model_r2)\n",
        "\n",
        " # Execute the main function\n",
        "if __name__ == \"__main__\":\n",
        " main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulJA6hVUyMux",
        "outputId": "fb782970-ac78-47ac-ec5a-e39a3a9c3e61"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Weights: [0.04797833 0.05020199]\n",
            "Cost History (First 10 iterations): [np.float64(4026.33114156751), 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "RMSE on Test Set: 63.36563528655014\n",
            "R-Squared on Test Set: -15.04041794561271\n"
          ]
        }
      ]
    }
  ]
}